{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN79ZEH1N69mpf0EBcgje/N"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gc-fia3Lxb1S","executionInfo":{"status":"ok","timestamp":1722412863794,"user_tz":-330,"elapsed":54784,"user":{"displayName":"Aniruddha Bolakhe","userId":"01672731812940932677"}},"outputId":"53fbcdda-bf7c-4079-cb9e-779bdecf2ea9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," time_distributed (TimeDist  (None, 20, 2, 2, 2048)    23564800  \n"," ributed)                                                        \n","                                                                 \n"," time_distributed_1 (TimeDi  (None, 20, 2048)          0         \n"," stributed)                                                      \n","                                                                 \n"," lstm (LSTM)                 (None, 32)                266368    \n","                                                                 \n"," dense (Dense)               (None, 3)                 99        \n","                                                                 \n","=================================================================\n","Total params: 23831267 (90.91 MB)\n","Trainable params: 266467 (1.02 MB)\n","Non-trainable params: 23564800 (89.89 MB)\n","_________________________________________________________________\n","Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.26.4)\n","Input shape: (1, 20, 64, 64, 3)\n","1/1 [==============================] - 3s 3s/step\n","Predicted action class index: 1\n","Predicted action class name: sensory_avoidance\n"]}],"source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Load the Model\n","import tensorflow as tf\n","\n","model_path = '/content/drive/MyDrive/LRCN_model___Date_Time_2024_07_31__07_44_19___Loss_0.3615138828754425___Accuracy_0.8733031749725342.h5'\n","model = tf.keras.models.load_model(model_path)\n","model.summary()  # Check model input shape\n","\n","# Install OpenCV\n","!pip install opencv-python-headless\n","\n","import cv2\n","import numpy as np\n","\n","def preprocess_video(video_path, img_size=(64, 64), max_frames=20):\n","    cap = cv2.VideoCapture(video_path)\n","    frames = []\n","\n","    while cap.isOpened() and len(frames) < max_frames:\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","        frame = cv2.resize(frame, img_size)\n","        frames.append(frame)\n","\n","    cap.release()\n","    cv2.destroyAllWindows()\n","\n","    # If fewer frames than max_frames, pad with zeros\n","    while len(frames) < max_frames:\n","        frames.append(np.zeros((img_size[0], img_size[1], 3)))\n","\n","    frames = np.array(frames) / 255.0\n","    frames = np.expand_dims(frames, axis=0)\n","\n","    return frames\n","\n","# Define the class names\n","class_names = [\"finger_sucking\", \"sensory_avoidance\", \"run&walk\"]  # Replace with your actual class names\n","\n","# Path to your video file\n","video_path = '/content/drive/MyDrive/10sec_video/run&walk/AED Running Scared - Autistic Children Running Away_part1.mp4'\n","\n","# Preprocess the video\n","frames = preprocess_video(video_path, img_size=(64, 64))\n","\n","# Check if the frames are in the expected shape\n","print(f'Input shape: {frames.shape}')\n","\n","# Predict the action\n","predictions = model.predict(frames)\n","\n","predicted_class_index = np.argmax(predictions, axis=-1)[0]\n","predicted_class_name = class_names[predicted_class_index]\n","\n","print(f'Predicted action class index: {predicted_class_index}')\n","print(f'Predicted action class name: {predicted_class_name}')"]}]}